{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f48f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample shape: (1000000, 45)\n",
      "\n",
      "=== Binary Classification ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gech\\AppData\\Local\\Temp\\ipykernel_8020\\3183301058.py:124: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  x = torch.tensor(x, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Graph constructed: 65304 nodes, 2000000 edges\n",
      "Binary Epoch 1, Train Loss: 0.6876, Val Loss: 0.4137, Train Acc: 0.5705, Val Acc: 0.9355\n",
      "Binary Epoch 2, Train Loss: 0.4026, Val Loss: 0.2644, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 3, Train Loss: 0.2714, Val Loss: 0.2851, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 4, Train Loss: 0.2867, Val Loss: 0.3014, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 5, Train Loss: 0.3052, Val Loss: 0.2764, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 6, Train Loss: 0.2814, Val Loss: 0.2430, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 7, Train Loss: 0.2446, Val Loss: 0.2233, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 8, Train Loss: 0.2314, Val Loss: 0.2194, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 9, Train Loss: 0.2219, Val Loss: 0.2243, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 10, Train Loss: 0.2241, Val Loss: 0.2293, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 11, Train Loss: 0.2285, Val Loss: 0.2304, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 12, Train Loss: 0.2318, Val Loss: 0.2273, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 13, Train Loss: 0.2276, Val Loss: 0.2211, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 14, Train Loss: 0.2225, Val Loss: 0.2140, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 15, Train Loss: 0.2169, Val Loss: 0.2081, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 16, Train Loss: 0.2079, Val Loss: 0.2048, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 17, Train Loss: 0.2035, Val Loss: 0.2039, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 18, Train Loss: 0.2126, Val Loss: 0.2030, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 19, Train Loss: 0.2080, Val Loss: 0.2005, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 20, Train Loss: 0.1999, Val Loss: 0.1964, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 21, Train Loss: 0.1987, Val Loss: 0.1913, Train Acc: 0.9358, Val Acc: 0.9355\n",
      "Binary Epoch 22, Train Loss: 0.1948, Val Loss: 0.1865, Train Acc: 0.9358, Val Acc: 0.9355\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load dataset with sampling\n",
    "csv_path = \"../dataset/NF_TON_IoT_V2/NF-ToN-IoT-v2.csv\"\n",
    "with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "    total_lines = sum(1 for _ in f) - 1  # Exclude header\n",
    "sample_size = 1_000_000\n",
    "lines_to_skip = sorted(random.sample(range(1, total_lines + 1), total_lines - sample_size))\n",
    "data = pd.read_csv(csv_path, skiprows=lines_to_skip)\n",
    "print(f\"Loaded sample shape: {data.shape}\")\n",
    "\n",
    "# Handle missing values\n",
    "for col in data.columns:\n",
    "    if data[col].dtype in ['int64', 'float64']:\n",
    "        data[col] = data[col].fillna(data[col].mean())\n",
    "    else:\n",
    "        data[col] = data[col].fillna(0)\n",
    "\n",
    "# Encode categorical features\n",
    "le_protocol = LabelEncoder()\n",
    "data['PROTOCOL'] = le_protocol.fit_transform(data['PROTOCOL'].astype(str))\n",
    "le_l7_proto = LabelEncoder()\n",
    "data['L7_PROTO'] = le_l7_proto.fit_transform(data['L7_PROTO'].astype(str))\n",
    "\n",
    "# Function to prepare data\n",
    "def prepare_data(df, mode='binary'):\n",
    "    if mode == 'binary':\n",
    "        y = df['Label'].values\n",
    "        num_classes = 2\n",
    "        le_attack = None\n",
    "        class_names = ['Benign', 'Attack']\n",
    "    elif mode == 'multiclass':\n",
    "        le_attack = LabelEncoder()\n",
    "        df['Attack'] = le_attack.fit_transform(df['Attack'].astype(str))\n",
    "        y = df['Attack'].values\n",
    "        unique_y = np.unique(y)\n",
    "        num_classes = len(unique_y)\n",
    "        label_map = {old: new for new, old in enumerate(unique_y)}\n",
    "        y = np.array([label_map[yi] for yi in y])\n",
    "        class_names = [le_attack.classes_[unique_y[i]] for i in range(num_classes)]\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'binary' or 'multiclass'\")\n",
    "\n",
    "    # Select numerical features (exclude Label, Attack, IP addresses, ports)\n",
    "    feature_cols = [col for col in df.columns if col not in ['Label', 'Attack', 'IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'L4_SRC_PORT', 'L4_DST_PORT']]\n",
    "    X = df[feature_cols].values\n",
    "\n",
    "    # Normalize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Create preprocessed DataFrame\n",
    "    df_processed = pd.DataFrame(X, columns=feature_cols)\n",
    "    df_processed[mode.capitalize()] = y\n",
    "    df_processed['L4_SRC_PORT'] = df['L4_SRC_PORT'].values\n",
    "    df_processed['L4_DST_PORT'] = df['L4_DST_PORT'].values\n",
    "\n",
    "    # Edge features\n",
    "    edge_feature_cols = ['IN_BYTES', 'OUT_BYTES', 'IN_PKTS', 'OUT_PKTS']\n",
    "    edge_features = df[edge_feature_cols].values\n",
    "    edge_scaler = StandardScaler()\n",
    "    edge_features = edge_scaler.fit_transform(edge_features)\n",
    "\n",
    "    return df_processed, y, num_classes, le_attack, class_names, edge_features, edge_feature_cols\n",
    "\n",
    "# Function for graph construction with edge features aggregated into nodes\n",
    "def build_graph(df_processed, y, edge_features, edge_feature_cols, mode):\n",
    "    src_ports = df_processed['L4_SRC_PORT'].values\n",
    "    dst_ports = df_processed['L4_DST_PORT'].values\n",
    "    unique_ports = np.unique(np.concatenate([src_ports, dst_ports]))\n",
    "    port_to_idx = {port: idx for idx, port in enumerate(unique_ports)}\n",
    "\n",
    "    node_features = defaultdict(list)\n",
    "    node_labels = defaultdict(list)\n",
    "    node_edge_features = defaultdict(list)  # To aggregate edge features per node\n",
    "    edge_index = []\n",
    "\n",
    "    for idx in range(len(df_processed)):\n",
    "        row = df_processed.iloc[idx]\n",
    "        src_port = row['L4_SRC_PORT']\n",
    "        dst_port = row['L4_DST_PORT']\n",
    "        features = row.drop([mode.capitalize(), 'L4_SRC_PORT', 'L4_DST_PORT']).values\n",
    "        label = row[mode.capitalize()]\n",
    "        src_idx = port_to_idx[src_port]\n",
    "        dst_idx = port_to_idx[dst_port]\n",
    "        node_features[src_idx].append(features)\n",
    "        node_features[dst_idx].append(features)\n",
    "        node_labels[src_idx].append(label)\n",
    "        node_labels[dst_idx].append(label)\n",
    "        node_edge_features[src_idx].append(edge_features[idx])\n",
    "        node_edge_features[dst_idx].append(edge_features[idx])\n",
    "        edge_index.append([src_idx, dst_idx])\n",
    "        edge_index.append([dst_idx, src_idx])\n",
    "\n",
    "    x = []\n",
    "    y_graph = []\n",
    "    for port_idx in range(len(unique_ports)):\n",
    "        if port_idx in node_features:\n",
    "            node_feats = np.mean(node_features[port_idx], axis=0)\n",
    "            edge_feats = np.mean(node_edge_features[port_idx], axis=0) if port_idx in node_edge_features else np.zeros(len(edge_feature_cols))\n",
    "            x.append(np.concatenate([node_feats, edge_feats]))  # Combine node and edge features\n",
    "            labels = node_labels[port_idx]\n",
    "            y_graph.append(np.bincount(labels).argmax())\n",
    "        else:\n",
    "            x.append(np.zeros(df_processed.shape[1] - 3 + len(edge_feature_cols)))\n",
    "            y_graph.append(0)\n",
    "\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    y_graph = torch.tensor(y_graph, dtype=torch.long)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    data_graph = Data(x=x, edge_index=edge_index, y=y_graph)\n",
    "    print(f\"{mode.capitalize()} Graph constructed: {data_graph.num_nodes} nodes, {data_graph.num_edges} edges\")\n",
    "\n",
    "    return data_graph\n",
    "\n",
    "# E-GraphSAGE model\n",
    "class EGraphSAGEModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(EGraphSAGEModel, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_features, 64)\n",
    "        self.conv2 = SAGEConv(64, 64)\n",
    "        self.fc = torch.nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_evaluate(model, data_graph, mode, num_classes, class_names, max_epochs=100, patience=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    # Masks\n",
    "    num_nodes = data_graph.num_nodes\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    indices = np.random.permutation(num_nodes)\n",
    "    train_size = int(0.6 * num_nodes)\n",
    "    val_size = int(0.2 * num_nodes)\n",
    "    train_mask[indices[:train_size]] = True\n",
    "    val_mask[indices[train_size:train_size + val_size]] = True\n",
    "    test_mask[indices[train_size + val_size:]] = True\n",
    "    data_graph.train_mask = train_mask\n",
    "    data_graph.val_mask = val_mask\n",
    "    data_graph.test_mask = test_mask\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data_graph)\n",
    "        loss = F.nll_loss(out[data_graph.train_mask], data_graph.y[data_graph.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        train_acc = accuracy_score(data_graph.y[data_graph.train_mask].numpy(), pred[data_graph.train_mask].numpy())\n",
    "        train_losses.append(loss.item())\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data_graph)\n",
    "            val_loss = F.nll_loss(out[data_graph.val_mask], data_graph.y[data_graph.val_mask])\n",
    "            val_pred = out.argmax(dim=1)\n",
    "            val_acc = accuracy_score(data_graph.y[data_graph.val_mask].numpy(), val_pred[data_graph.val_mask].numpy())\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f'{mode.capitalize()} Epoch {epoch + 1}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'{mode.capitalize()} Early stopping at epoch {epoch + 1}')\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Plots for accuracy and loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_accuracies, label='Train Acc')\n",
    "    plt.plot(val_accuracies, label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{mode.capitalize()} Training vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{mode.capitalize()} Training vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{mode}_acc_loss.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data_graph)\n",
    "        pred = out.argmax(dim=1)\n",
    "        y_true = data_graph.y[data_graph.test_mask].numpy()\n",
    "        y_pred = pred[data_graph.test_mask].numpy()\n",
    "        y_score = out[data_graph.test_mask].numpy()\n",
    "\n",
    "        test_classes = np.unique(y_true)\n",
    "        test_class_names = [class_names[i] for i in test_classes]\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='weighted', labels=test_classes)\n",
    "        recall = recall_score(y_true, y_pred, average='weighted', labels=test_classes)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted', labels=test_classes)\n",
    "\n",
    "        print(f\"\\n{mode.capitalize()} Classification Report:\")\n",
    "        print(classification_report(y_true, y_pred, labels=test_classes, target_names=test_class_names))\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=test_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_class_names, yticklabels=test_class_names)\n",
    "        plt.title(f'{mode.capitalize()} Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(f'{mode}_confusion_matrix.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        if mode == 'binary':\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_score[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'{mode.capitalize()} ROC Curve')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.savefig(f'{mode}_roc_curve.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        else:\n",
    "            y_true_bin = label_binarize(y_true, classes=range(num_classes))\n",
    "            plt.figure()\n",
    "            for i in test_classes:\n",
    "                fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                plt.plot(fpr, tpr, label=f'Class {test_class_names[list(test_classes).index(i)]} (AUC = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'{mode.capitalize()} ROC Curve (One-vs-Rest)')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.savefig(f'{mode}_roc_curve.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    print(f\"\\n{mode.capitalize()} Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (weighted): {recall:.4f}\")\n",
    "    print(f\"F1 (weighted): {f1:.4f}\")\n",
    "\n",
    "# Binary classification\n",
    "print(\"\\n=== Binary Classification ===\")\n",
    "df_processed_bin, y_bin, num_classes_bin, _, class_names_bin, edge_features_bin, edge_feature_cols = prepare_data(data, mode='binary')\n",
    "data_graph_bin = build_graph(df_processed_bin, y_bin, edge_features_bin, edge_feature_cols, 'binary')\n",
    "model_bin = EGraphSAGEModel(data_graph_bin.num_features, num_classes_bin)\n",
    "train_evaluate(model_bin, data_graph_bin, 'binary', num_classes_bin, class_names_bin)\n",
    "\n",
    "# Multiclass classification\n",
    "print(\"\\n=== Multiclass Classification ===\")\n",
    "df_processed_multi, y_multi, num_classes_multi, le_attack_multi, class_names_multi, edge_features_multi, edge_feature_cols = prepare_data(data, mode='multiclass')\n",
    "data_graph_multi = build_graph(df_processed_multi, y_multi, edge_features_multi, edge_feature_cols, 'multiclass')\n",
    "model_multi = EGraphSAGEModel(data_graph_multi.num_features, num_classes_multi)\n",
    "train_evaluate(model_multi, data_graph_multi, 'multiclass', num_classes_multi, class_names_multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf28aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score, accuracy_score\n",
    "from os import cpu_count\n",
    "from math import floor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# import shap\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea579c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../dataset/NF_TON_IoT_V2/NF-ToN-IoT-v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L4_SRC_PORT</th>\n",
       "      <th>L4_DST_PORT</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "      <th>Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2017</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4762</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>280</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32534</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>280</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13423</td>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "      <td>188.0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-28756</td>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "      <td>188.0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   L4_SRC_PORT  L4_DST_PORT  PROTOCOL  L7_PROTO  IN_BYTES  IN_PKTS  OUT_BYTES  \\\n",
       "0        -2017           80         6       7.0       140        1          0   \n",
       "1        -4762           80         6       7.0       280        2          0   \n",
       "2        32534           80         6       7.0       280        2          0   \n",
       "3       -13423           80        17     188.0        56        2          0   \n",
       "4       -28756           80        17     188.0        56        2          0   \n",
       "\n",
       "   OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  ...  TCP_WIN_MAX_IN  \\\n",
       "0         0          2                 2  ...             512   \n",
       "1         0          2                 2  ...             512   \n",
       "2         0          2                 2  ...             512   \n",
       "3         0          0                 0  ...               0   \n",
       "4         0          0                 0  ...               0   \n",
       "\n",
       "   TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0                0          0               0             0               0   \n",
       "1                0          0               0             0               0   \n",
       "2                0          0               0             0               0   \n",
       "3                0          0               0             0               0   \n",
       "4                0          0               0             0               0   \n",
       "\n",
       "   DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  Label  Attack  \n",
       "0               0                   0.0      1     DoS  \n",
       "1               0                   0.0      1     DoS  \n",
       "2               0                   0.0      1     DoS  \n",
       "3               0                   0.0      1    DDoS  \n",
       "4               0                   0.0      1    DDoS  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L4_SRC_PORT                      int16\n",
       "L4_DST_PORT                      int16\n",
       "PROTOCOL                          int8\n",
       "L7_PROTO                       float32\n",
       "IN_BYTES                         int32\n",
       "IN_PKTS                          int32\n",
       "OUT_BYTES                        int32\n",
       "OUT_PKTS                         int32\n",
       "TCP_FLAGS                        int16\n",
       "CLIENT_TCP_FLAGS                 int16\n",
       "SERVER_TCP_FLAGS                 int16\n",
       "FLOW_DURATION_MILLISECONDS       int32\n",
       "DURATION_IN                      int16\n",
       "DURATION_OUT                     int16\n",
       "MIN_TTL                          int16\n",
       "MAX_TTL                          int16\n",
       "LONGEST_FLOW_PKT                 int32\n",
       "SHORTEST_FLOW_PKT                int16\n",
       "MIN_IP_PKT_LEN                   int16\n",
       "MAX_IP_PKT_LEN                   int32\n",
       "SRC_TO_DST_SECOND_BYTES        float32\n",
       "DST_TO_SRC_SECOND_BYTES        float32\n",
       "RETRANSMITTED_IN_BYTES           int32\n",
       "RETRANSMITTED_IN_PKTS            int16\n",
       "RETRANSMITTED_OUT_BYTES          int16\n",
       "RETRANSMITTED_OUT_PKTS            int8\n",
       "SRC_TO_DST_AVG_THROUGHPUT        int64\n",
       "DST_TO_SRC_AVG_THROUGHPUT        int64\n",
       "NUM_PKTS_UP_TO_128_BYTES         int16\n",
       "NUM_PKTS_128_TO_256_BYTES        int16\n",
       "NUM_PKTS_256_TO_512_BYTES        int16\n",
       "NUM_PKTS_512_TO_1024_BYTES       int32\n",
       "NUM_PKTS_1024_TO_1514_BYTES      int32\n",
       "TCP_WIN_MAX_IN                   int32\n",
       "TCP_WIN_MAX_OUT                  int32\n",
       "ICMP_TYPE                        int32\n",
       "ICMP_IPV4_TYPE                   int16\n",
       "DNS_QUERY_ID                     int32\n",
       "DNS_QUERY_TYPE                   int16\n",
       "DNS_TTL_ANSWER                   int32\n",
       "FTP_COMMAND_RET_CODE           float32\n",
       "Label                             int8\n",
       "Attack                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce873e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30290649\n",
       "0      129437\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e5bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDoS              14280259\n",
       "DoS               13645057\n",
       "Reconnaissance     2363017\n",
       "Benign              129437\n",
       "Theft                 2316\n",
       "Name: Attack, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcaec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['L4_SRC_PORT', 'L4_DST_PORT']) #dropping metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = data.sample(frac=0.05, replace=False,random_state=42)\n",
    "# 1%train, 99% test\n",
    "testing_set = data.drop(index=training_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c1ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDoS              713308\n",
       "DoS               682874\n",
       "Reconnaissance    118292\n",
       "Benign              6425\n",
       "Theft                105\n",
       "Name: Attack, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b8d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks=training_set.Attack.unique()\n",
    "attacks=['Benign','Reconnaissance', 'DDoS', 'DoS', 'Theft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = training_set.corr()\n",
    "corr_features={corr.columns[i] : corr.columns[(corr>0.9).iloc[i]].values.tolist() for i in range(0,corr.shape[0])}\n",
    "corr_list=[]\n",
    "for key,value in corr_features.items():\n",
    "#     check if we already have this set\n",
    "    have_set=False\n",
    "    for set_s in corr_list:\n",
    "        if key in set_s:\n",
    "#             we have found a set\n",
    "            have_set=True\n",
    "            break\n",
    "    if have_set==False and len(value)>1:\n",
    "        corr_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f90e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PROTOCOL', 'L7_PROTO'],\n",
       " ['IN_BYTES',\n",
       "  'IN_PKTS',\n",
       "  'NUM_PKTS_512_TO_1024_BYTES',\n",
       "  'NUM_PKTS_1024_TO_1514_BYTES'],\n",
       " ['OUT_BYTES', 'OUT_PKTS', 'NUM_PKTS_1024_TO_1514_BYTES'],\n",
       " ['TCP_FLAGS', 'SERVER_TCP_FLAGS', 'MIN_IP_PKT_LEN'],\n",
       " ['MIN_TTL', 'MAX_TTL'],\n",
       " ['LONGEST_FLOW_PKT', 'MAX_IP_PKT_LEN'],\n",
       " ['RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS'],\n",
       " ['RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS'],\n",
       " ['ICMP_TYPE', 'ICMP_IPV4_TYPE']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631a793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PROTOCOL', 'L7_PROTO'],\n",
       " ['IN_BYTES',\n",
       "  'IN_PKTS',\n",
       "  'NUM_PKTS_512_TO_1024_BYTES',\n",
       "  'NUM_PKTS_1024_TO_1514_BYTES'],\n",
       " ['OUT_BYTES', 'OUT_PKTS'],\n",
       " ['TCP_FLAGS', 'SERVER_TCP_FLAGS', 'MIN_IP_PKT_LEN'],\n",
       " ['MIN_TTL', 'MAX_TTL'],\n",
       " ['LONGEST_FLOW_PKT', 'MAX_IP_PKT_LEN'],\n",
       " ['RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS'],\n",
       " ['RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS'],\n",
       " ['ICMP_TYPE', 'ICMP_IPV4_TYPE']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correction because NUM_PKTS_1024_TO_1514_BYTES appears twice\n",
    "corr_list[2]=corr_list[2][:-1]\n",
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f8ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in c:\\users\\gech\\anaconda3\\lib\\site-packages (2.6.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: aiohttp in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (3.8.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (2023.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (2.11.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (2.29.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from jinja2->torch-geometric) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\gech\\anaconda3\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\gech\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gech\\anaconda3\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\gech\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eef436",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch_geometric' has no attribute 'typing' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GATConv\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "File \u001b[1;32mc:\\Users\\gech\\anaconda3\\lib\\site-packages\\torch_geometric\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhome\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_home_dir, set_home_dir\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_mps_available, is_xpu_available, device\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01misinstance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_instance\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_debug_enabled, debug, set_debug\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gech\\anaconda3\\lib\\site-packages\\torch_geometric\\isinstance.py:7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch_geometric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtyping\u001b[49m\u001b[38;5;241m.\u001b[39mWITH_PT20:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_torch_instance\u001b[39m(obj: Any, \u001b[38;5;28mcls\u001b[39m: Union[Type, Tuple[Type]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch_geometric' has no attribute 'typing' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71ce8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GATConv\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Data Loading and Preprocessing\n",
    "def load_and_preprocess_data(file_path):\n",
    "    # Load data\n",
    "    data = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Handle negative port values\n",
    "    data['L4_SRC_PORT'] = data['L4_SRC_PORT'].abs()\n",
    "    data['L4_DST_PORT'] = data['L4_DST_PORT'].abs()\n",
    "    \n",
    "    # Select numerical features\n",
    "    numerical_features = [\n",
    "        'L4_SRC_PORT', 'L4_DST_PORT', 'IN_BYTES', 'IN_PKTS', \n",
    "        'OUT_BYTES', 'OUT_PKTS', 'TCP_WIN_MAX_IN', 'TCP_WIN_MAX_OUT'\n",
    "    ]\n",
    "    \n",
    "    # Handle missing values\n",
    "    data[numerical_features] = data[numerical_features].fillna(0)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_attack = LabelEncoder()\n",
    "    data['Attack_encoded'] = le_attack.fit_transform(data['Attack'])\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "    \n",
    "    return data, numerical_features, le_attack\n",
    "\n",
    "# 2. Exploratory Data Analysis\n",
    "def perform_eda(data, numerical_features):\n",
    "    print(\"\\nEDA Summary:\")\n",
    "    print(\"\\nDataset Shape:\", data.shape)\n",
    "    print(\"\\nMissing Values:\\n\", data.isnull().sum().sum())\n",
    "    print(\"\\nLabel Distribution:\\n\", data['Label'].value_counts())\n",
    "    print(\"\\nAttack Type Distribution:\\n\", data['Attack'].value_counts())\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(data[numerical_features].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.savefig('correlation_heatmap.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Attack type distribution plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='Attack', data=data)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Attack Type Distribution')\n",
    "    plt.savefig('attack_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "# 3. Graph Construction\n",
    "def create_graph_data(data, numerical_features, target_col='Label'):\n",
    "    # Create edge index based on similar source/destination ports\n",
    "    edge_index = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i+1, len(data)):\n",
    "            if (data.iloc[i]['L4_SRC_PORT'] == data.iloc[j]['L4_SRC_PORT'] or \n",
    "                data.iloc[i]['L4_DST_PORT'] == data.iloc[j]['L4_DST_PORT']):\n",
    "                edge_index.append([i, j])\n",
    "                edge_index.append([j, i])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Node features\n",
    "    x = torch.tensor(data[numerical_features].values, dtype=torch.float)\n",
    "    \n",
    "    # Labels\n",
    "    y = torch.tensor(data[target_col].values, dtype=torch.long)\n",
    "    \n",
    "    # Create PyG data object\n",
    "    graph_data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    # Create train/test mask\n",
    "    train_mask, test_mask = train_test_split(\n",
    "        range(len(data)), test_size=0.2, random_state=42, stratify=data[target_col]\n",
    "    )\n",
    "    graph_data.train_mask = torch.tensor(train_mask, dtype=torch.long)\n",
    "    graph_data.test_mask = torch.tensor(test_mask, dtype=torch.long)\n",
    "    \n",
    "    return graph_data\n",
    "\n",
    "# 4. Attention-based GNN Model\n",
    "class AttentionGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=4):\n",
    "        super(AttentionGNN, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads)\n",
    "        self.fc1 = nn.Linear(hidden_dim * heads, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# 5. Training Function\n",
    "def train_model(model, data, optimizer, criterion, epochs=100):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# 6. Evaluation Function\n",
    "def evaluate_model(model, data, le_attack=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(data).argmax(dim=1)\n",
    "        \n",
    "        # Get true and predicted labels\n",
    "        y_true = data.y[data.test_mask].numpy()\n",
    "        y_pred = pred[data.test_mask].numpy()\n",
    "        \n",
    "        # Classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        if le_attack is not None:\n",
    "            target_names = le_attack.classes_\n",
    "        else:\n",
    "            target_names = ['Benign', 'Malicious']\n",
    "        print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # ROC AUC for binary classification\n",
    "        if len(np.unique(data.y)) == 2:\n",
    "            probs = torch.softmax(model(data), dim=1)[:, 1]\n",
    "            roc_auc = roc_auc_score(y_true, probs[data.test_mask].numpy())\n",
    "            print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    file_path = \"../dataset/NF-BoT-IoT-V2.parquet\"\n",
    "    data, numerical_features, le_attack = load_and_preprocess_data(file_path)\n",
    "    \n",
    "    # Perform EDA\n",
    "    perform_eda(data, numerical_features)\n",
    "    \n",
    "    # Binary Classification\n",
    "    print(\"\\n=== Binary Classification ===\")\n",
    "    binary_graph = create_graph_data(data, numerical_features, 'Label')\n",
    "    \n",
    "    # Initialize model\n",
    "    binary_model = AttentionGNN(\n",
    "        input_dim=len(numerical_features),\n",
    "        hidden_dim=64,\n",
    "        output_dim=2\n",
    "    )\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = torch.optim.Adam(binary_model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train model\n",
    "    binary_losses = train_model(binary_model, binary_graph, optimizer, criterion)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(binary_model, binary_graph)\n",
    "    \n",
    "    # Multiclass Classification\n",
    "    print(\"\\n=== Multiclass Classification ===\")\n",
    "    multiclass_graph = create_graph_data(data, numerical_features, 'Attack_encoded')\n",
    "    \n",
    "    # Initialize model\n",
    "    multiclass_model = AttentionGNN(\n",
    "        input_dim=len(numerical_features),\n",
    "        hidden_dim=64,\n",
    "        output_dim=len(le_attack.classes_)\n",
    "    )\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = torch.optim.Adam(multiclass_model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train model\n",
    "    multiclass_losses = train_model(multiclass_model, multiclass_graph, optimizer, criterion)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(multiclass_model, multiclass_graph, le_attack)\n",
    "    \n",
    "    # Plot training losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(binary_losses, label='Binary Classification')\n",
    "    plt.plot(multiclass_losses, label='Multiclass Classification')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.savefig('training_loss.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a1a3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (1000000, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gech\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1120: RuntimeWarning: overflow encountered in square\n",
      "  temp **= 2\n",
      "c:\\Users\\gech\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1126: RuntimeWarning: overflow encountered in square\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "c:\\Users\\gech\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1126: RuntimeWarning: invalid value encountered in subtract\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "c:\\Users\\gech\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:81: RuntimeWarning: overflow encountered in square\n",
      "  upper_bound = n_samples * eps * var + (n_samples * mean * eps) ** 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset shape: (1000000, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gech\\AppData\\Local\\Temp\\ipykernel_3348\\1095886239.py:82: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  x = torch.tensor(x, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph constructed: 65532 nodes, 2000000 edges\n",
      "\n",
      "Training GraphSAGE...\n",
      "GraphSAGE Epoch 1, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Epoch 2, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Epoch 3, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Epoch 4, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Epoch 5, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Epoch 6, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Epoch 7, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Epoch 8, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Epoch 9, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Epoch 10, Train Loss: nan, Val Loss: nan, Train Acc: 0.2922, Val Acc: 0.3026\n",
      "GraphSAGE Early stopping at epoch 10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'NoneType'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 308\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 308\u001b[0m     results[name] \u001b[38;5;241m=\u001b[39m train_and_evaluate(model, data, name)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# Model comparison plots (combined)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[1;32mIn[2], line 232\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, data, model_name, max_epochs, patience)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Load best model for evaluation\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(best_model_state)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Plot training vs validation accuracy and loss for this model\u001b[39;00m\n\u001b[0;32m    235\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\gech\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2525\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2488\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m \n\u001b[0;32m   2490\u001b[0m \u001b[38;5;124;03mIf :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2522\u001b[0m \u001b[38;5;124;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[0;32m   2523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[1;32m-> 2525\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2527\u001b[0m     )\n\u001b[0;32m   2529\u001b[0m missing_keys: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2530\u001b[0m unexpected_keys: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'NoneType'>."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv, GCNConv, GATConv\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load 1 million rows from dataset\n",
    "df = pd.read_csv(\"../dataset/NF_TON_IoT_V2/NF-ToN-IoT-v2.csv\", nrows=1_000_000)\n",
    "print(f\"Loaded dataset shape: {df.shape}\")\n",
    "\n",
    "# Handle missing values and convert numerical columns to float64\n",
    "for col in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):  # Check for any numeric type (int, float, etc.)\n",
    "        df[col] = df[col].astype('float64').fillna(df[col].mean())\n",
    "    else:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "# Encode categorical features\n",
    "le_protocol = LabelEncoder()\n",
    "df['PROTOCOL'] = le_protocol.fit_transform(df['PROTOCOL'].astype(str))\n",
    "le_l7_proto = LabelEncoder()\n",
    "df['L7_PROTO'] = le_l7_proto.fit_transform(df['L7_PROTO'].astype(str))\n",
    "\n",
    "# Extract labels for binary classification\n",
    "y = df['Label'].values\n",
    "\n",
    "# Feature selection: exclude non-numerical columns and 'Label', 'Attack'\n",
    "non_numerical_cols = ['IPV4_SRC_ADDR', 'IPV4_DST_ADDR']  # Common IP address columns\n",
    "feature_cols = [col for col in df.columns if col not in ['Label', 'Attack'] + non_numerical_cols and pd.api.types.is_numeric_dtype(df[col])]\n",
    "X = df[feature_cols].values\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Create preprocessed DataFrame\n",
    "df_processed = pd.DataFrame(X, columns=feature_cols)\n",
    "df_processed['Label'] = y\n",
    "df_processed['L4_SRC_PORT'] = df['L4_SRC_PORT'].values\n",
    "df_processed['L4_DST_PORT'] = df['L4_DST_PORT'].values\n",
    "print(f\"Preprocessed dataset shape: {df_processed.shape}\")\n",
    "\n",
    "# Graph construction\n",
    "src_ports = df_processed['L4_SRC_PORT'].values\n",
    "dst_ports = df_processed['L4_DST_PORT'].values\n",
    "unique_ports = np.unique(np.concatenate([src_ports, dst_ports]))\n",
    "port_to_idx = {port: idx for idx, port in enumerate(unique_ports)}\n",
    "\n",
    "# Aggregate node features and labels\n",
    "node_features = defaultdict(list)\n",
    "node_labels = defaultdict(list)\n",
    "for idx in range(len(df_processed)):\n",
    "    row = df_processed.iloc[idx]\n",
    "    src_port = row['L4_SRC_PORT']\n",
    "    dst_port = row['L4_DST_PORT']\n",
    "    features = row.drop(['Label', 'L4_SRC_PORT', 'L4_DST_PORT']).values\n",
    "    label = row['Label']\n",
    "    node_features[port_to_idx[src_port]].append(features[:-1])\n",
    "    node_features[port_to_idx[dst_port]].append(features[:-1])\n",
    "    node_labels[port_to_idx[src_port]].append(label)\n",
    "    node_labels[port_to_idx[dst_port]].append(label)\n",
    "\n",
    "# Compute average features and labels per node\n",
    "x = []\n",
    "y = []\n",
    "for port_idx in range(len(unique_ports)):\n",
    "    if port_idx in node_features:\n",
    "        x.append(np.mean(node_features[port_idx], axis=0))\n",
    "        y.append(np.mean(node_labels[port_idx]))\n",
    "    else:\n",
    "        x.append(np.zeros(df_processed.shape[1] - 3))\n",
    "        y.append(0)\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Construct edges (bidirectional)\n",
    "edge_index = []\n",
    "for idx in range(len(df_processed)):\n",
    "    row = df_processed.iloc[idx]\n",
    "    src_idx = port_to_idx[row['L4_SRC_PORT']]\n",
    "    dst_idx = port_to_idx[row['L4_DST_PORT']]\n",
    "    edge_index.append([src_idx, dst_idx])\n",
    "    edge_index.append([dst_idx, src_idx])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create PyTorch Geometric Data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "print(f\"Graph constructed: {data.num_nodes} nodes, {data.num_edges} edges\")\n",
    "\n",
    "# Create train/val/test masks (70% train, 10% val, 20% test)\n",
    "num_nodes = data.num_nodes\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "indices = np.random.permutation(num_nodes)\n",
    "train_size = int(0.7 * num_nodes)\n",
    "val_size = int(0.1 * num_nodes)\n",
    "train_mask[indices[:train_size]] = True\n",
    "val_mask[indices[train_size:train_size + val_size]] = True\n",
    "test_mask[indices[train_size + val_size:]] = True\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "# Model definitions\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(data.num_features, 64)\n",
    "        self.conv2 = SAGEConv(64, 64)\n",
    "        self.fc = torch.nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(data.num_features, 64)\n",
    "        self.conv2 = GCNConv(64, 64)\n",
    "        self.fc = torch.nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(data.num_features, 32, heads=2)\n",
    "        self.conv2 = GATConv(32 * 2, 64, heads=1)\n",
    "        self.fc = torch.nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(data.num_features, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Training and evaluation function with early stopping\n",
    "def train_and_evaluate(model, data, model_name, max_epochs=100, patience=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute training metrics\n",
    "        pred = out.argmax(dim=1)\n",
    "        train_acc = accuracy_score(data.y[data.train_mask].numpy(), pred[data.train_mask].numpy())\n",
    "        train_losses.append(loss.item())\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # Compute validation metrics\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            val_loss = F.nll_loss(out[data.val_mask], data.y[data.val_mask])\n",
    "            val_pred = out.argmax(dim=1)\n",
    "            val_acc = accuracy_score(data.y[data.val_mask].numpy(), val_pred[data.val_mask].numpy())\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_accuracies.append(val_acc)\n",
    "\n",
    "        # Print metrics for every epoch\n",
    "        print(f'{model_name} Epoch {epoch + 1}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'{model_name} Early stopping at epoch {epoch + 1}')\n",
    "                break\n",
    "\n",
    "    # Load best model for evaluation\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Plot training vs validation accuracy and loss for this model\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_accuracies, label='Train Acc')\n",
    "    plt.plot(val_accuracies, label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{model_name} Training vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{model_name} Training vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_acc_loss.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        y_true = data.y[data.test_mask].numpy()\n",
    "        y_pred = pred[data.test_mask].numpy()\n",
    "        y_score = out[data.test_mask][:, 1].numpy()\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='binary')\n",
    "        recall = recall_score(y_true, y_pred, average='binary')\n",
    "        f1 = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'{model_name} Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(f'{model_name}_confusion_matrix.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'{model_name} ROC Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(f'{model_name}_roc_curve.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'roc_auc': roc_auc,\n",
    "            'train_losses': train_losses, 'val_losses': val_losses, 'train_accuracies': train_accuracies, 'val_accuracies': val_accuracies}\n",
    "\n",
    "# Train and evaluate all models\n",
    "models = {\n",
    "    'GraphSAGE': GraphSAGE(),\n",
    "    'GCN': GCN(),\n",
    "    'GAT': GAT(),\n",
    "    'MLP': MLP()\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    results[name] = train_and_evaluate(model, data, name)\n",
    "\n",
    "# Model comparison plots (combined)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "for name in models:\n",
    "    plt.plot(results[name]['train_accuracies'], label=f'{name} Train')\n",
    "    plt.plot(results[name]['val_accuracies'], '--', label=f'{name} Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy Comparison')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "for name in models:\n",
    "    plt.plot(results[name]['train_losses'], label=f'{name} Train')\n",
    "    plt.plot(results[name]['val_losses'], '--', label=f'{name} Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Comparison')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nModel Comparison Metrics:\")\n",
    "for name in models:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Accuracy: {results[name]['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results[name]['precision']:.4f}\")\n",
    "    print(f\"Recall: {results[name]['recall']:.4f}\")\n",
    "    print(f\"F1: {results[name]['f1']:.4f}\")\n",
    "    print(f\"ROC AUC: {results[name]['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3febcd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
