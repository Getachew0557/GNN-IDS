{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6615ff8",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b44b00f",
   "metadata": {},
   "source": [
    "### Import Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf28aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score, accuracy_score\n",
    "from os import cpu_count\n",
    "from math import floor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# import shap\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671219f",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea579c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample shape: (999999, 45)\n"
     ]
    }
   ],
   "source": [
    "#data=pd.read_csv(\"../dataset/NF_TON_IoT_V2/NF-ToN-IoT-v2.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# File path\n",
    "csv_path = \"../dataset/NF_TON_IoT_V2/NF-ToN-IoT-v2.csv\"\n",
    "\n",
    "# STEP 1: Count total rows (without loading the file into memory)\n",
    "with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "# STEP 2: Calculate how many lines to skip\n",
    "sample_size = 1_000_000\n",
    "lines_to_skip = sorted(random.sample(range(1, total_lines), total_lines - sample_size))\n",
    "\n",
    "# STEP 3: Read just 1 million rows (skip most lines except header)\n",
    "data = pd.read_csv(csv_path, skiprows=lines_to_skip)\n",
    "\n",
    "# Confirm result\n",
    "print(f\"Loaded sample shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2d727",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d2187",
   "metadata": {},
   "source": [
    "### Summary of Stastics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb1e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>L4_SRC_PORT</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>L4_DST_PORT</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "      <th>Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>51466</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>15600</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.1.193</td>\n",
       "      <td>64035</td>\n",
       "      <td>8.8.8.8</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>5.126</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3579</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>53929</td>\n",
       "      <td>192.168.1.255</td>\n",
       "      <td>15600</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.1.193</td>\n",
       "      <td>49220</td>\n",
       "      <td>192.168.1.33</td>\n",
       "      <td>4444</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>151312</td>\n",
       "      <td>200</td>\n",
       "      <td>87548</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>16425</td>\n",
       "      <td>2941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ransomware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.1.193</td>\n",
       "      <td>49236</td>\n",
       "      <td>192.168.1.37</td>\n",
       "      <td>4444</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>168880</td>\n",
       "      <td>214</td>\n",
       "      <td>38472</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>16425</td>\n",
       "      <td>2898</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ransomware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IPV4_SRC_ADDR  L4_SRC_PORT    IPV4_DST_ADDR  L4_DST_PORT  PROTOCOL  \\\n",
       "0   192.168.1.79        51466  239.255.255.250        15600        17   \n",
       "1  192.168.1.193        64035          8.8.8.8           53        17   \n",
       "2   192.168.1.79        53929    192.168.1.255        15600        17   \n",
       "3  192.168.1.193        49220     192.168.1.33         4444         6   \n",
       "4  192.168.1.193        49236     192.168.1.37         4444         6   \n",
       "\n",
       "   L7_PROTO  IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  ...  TCP_WIN_MAX_IN  \\\n",
       "0     0.000        63        1          0         0  ...               0   \n",
       "1     5.126        58        1         90         1  ...               0   \n",
       "2     0.000        63        1          0         0  ...               0   \n",
       "3     0.000    151312      200      87548       167  ...           16425   \n",
       "4     0.000    168880      214      38472       151  ...           16425   \n",
       "\n",
       "   TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0                0          0               0             0               0   \n",
       "1                0          0               0          3579               1   \n",
       "2                0          0               0             0               0   \n",
       "3             2941          0               0             0               0   \n",
       "4             2898          0               0             0               0   \n",
       "\n",
       "   DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  Label      Attack  \n",
       "0               0                     0      0      Benign  \n",
       "1             299                     0      0      Benign  \n",
       "2               0                     0      0      Benign  \n",
       "3               0                     0      1  ransomware  \n",
       "4               0                     0      1  ransomware  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad56ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPV4_SRC_ADDR                   object\n",
       "L4_SRC_PORT                      int64\n",
       "IPV4_DST_ADDR                   object\n",
       "L4_DST_PORT                      int64\n",
       "PROTOCOL                         int64\n",
       "L7_PROTO                       float64\n",
       "IN_BYTES                         int64\n",
       "IN_PKTS                          int64\n",
       "OUT_BYTES                        int64\n",
       "OUT_PKTS                         int64\n",
       "TCP_FLAGS                        int64\n",
       "CLIENT_TCP_FLAGS                 int64\n",
       "SERVER_TCP_FLAGS                 int64\n",
       "FLOW_DURATION_MILLISECONDS       int64\n",
       "DURATION_IN                      int64\n",
       "DURATION_OUT                     int64\n",
       "MIN_TTL                          int64\n",
       "MAX_TTL                          int64\n",
       "LONGEST_FLOW_PKT                 int64\n",
       "SHORTEST_FLOW_PKT                int64\n",
       "MIN_IP_PKT_LEN                   int64\n",
       "MAX_IP_PKT_LEN                   int64\n",
       "SRC_TO_DST_SECOND_BYTES        float64\n",
       "DST_TO_SRC_SECOND_BYTES        float64\n",
       "RETRANSMITTED_IN_BYTES           int64\n",
       "RETRANSMITTED_IN_PKTS            int64\n",
       "RETRANSMITTED_OUT_BYTES          int64\n",
       "RETRANSMITTED_OUT_PKTS           int64\n",
       "SRC_TO_DST_AVG_THROUGHPUT        int64\n",
       "DST_TO_SRC_AVG_THROUGHPUT        int64\n",
       "NUM_PKTS_UP_TO_128_BYTES         int64\n",
       "NUM_PKTS_128_TO_256_BYTES        int64\n",
       "NUM_PKTS_256_TO_512_BYTES        int64\n",
       "NUM_PKTS_512_TO_1024_BYTES       int64\n",
       "NUM_PKTS_1024_TO_1514_BYTES      int64\n",
       "TCP_WIN_MAX_IN                   int64\n",
       "TCP_WIN_MAX_OUT                  int64\n",
       "ICMP_TYPE                        int64\n",
       "ICMP_IPV4_TYPE                   int64\n",
       "DNS_QUERY_ID                     int64\n",
       "DNS_QUERY_TYPE                   int64\n",
       "DNS_TTL_ANSWER                   int64\n",
       "FTP_COMMAND_RET_CODE             int64\n",
       "Label                            int64\n",
       "Attack                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ce873e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    639952\n",
       "0    360047\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7e5bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack\n",
       "Benign        360047\n",
       "scanning      222925\n",
       "xss           144988\n",
       "ddos          119472\n",
       "password       68375\n",
       "dos            42024\n",
       "injection      40518\n",
       "backdoor         977\n",
       "mitm             468\n",
       "ransomware       205\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcaec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['L4_SRC_PORT', 'L4_DST_PORT']) #dropping metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d96873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = data.sample(frac=0.05, replace=False,random_state=42)\n",
    "# 1%train, 99% test\n",
    "testing_set = data.drop(index=training_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "324c1ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack\n",
       "Benign        18040\n",
       "scanning      11293\n",
       "xss            7194\n",
       "ddos           5902\n",
       "password       3403\n",
       "dos            2063\n",
       "injection      2024\n",
       "backdoor         56\n",
       "mitm             13\n",
       "ransomware       12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b8d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks=training_set.Attack.unique()\n",
    "attacks=['Benign','Reconnaissance', 'DDoS', 'DoS', 'Theft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a08dc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1: ['IN_BYTES', 'IN_PKTS', 'OUT_BYTES', 'RETRANSMITTED_OUT_BYTES', 'NUM_PKTS_1024_TO_1514_BYTES']\n",
      "Group 2: ['TCP_FLAGS', 'SERVER_TCP_FLAGS']\n",
      "Group 3: ['MIN_TTL', 'MAX_TTL']\n",
      "Group 4: ['LONGEST_FLOW_PKT', 'MAX_IP_PKT_LEN']\n",
      "Group 5: ['RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS']\n",
      "Group 6: ['ICMP_TYPE', 'ICMP_IPV4_TYPE']\n"
     ]
    }
   ],
   "source": [
    "# --- Compute correlation only for numeric features ---\n",
    "corr = training_set.select_dtypes(include='number').corr()\n",
    "\n",
    "# Find highly correlated features (> 0.9)\n",
    "corr_features = {\n",
    "    corr.columns[i]: corr.columns[(corr > 0.9).iloc[i]].values.tolist()\n",
    "    for i in range(corr.shape[0])\n",
    "}\n",
    "\n",
    "# Group correlated features into sets (no duplicates)\n",
    "corr_list = []\n",
    "for key, value in corr_features.items():\n",
    "    have_set = any(key in s for s in corr_list)\n",
    "    if not have_set and len(value) > 1:\n",
    "        corr_list.append(value)\n",
    "\n",
    "# Output the groups of highly correlated features\n",
    "for i, group in enumerate(corr_list, 1):\n",
    "    print(f\"Group {i}: {group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f90e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['IN_BYTES',\n",
       "  'IN_PKTS',\n",
       "  'OUT_BYTES',\n",
       "  'RETRANSMITTED_OUT_BYTES',\n",
       "  'NUM_PKTS_1024_TO_1514_BYTES'],\n",
       " ['TCP_FLAGS', 'SERVER_TCP_FLAGS'],\n",
       " ['MIN_TTL', 'MAX_TTL'],\n",
       " ['LONGEST_FLOW_PKT', 'MAX_IP_PKT_LEN'],\n",
       " ['RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS'],\n",
       " ['ICMP_TYPE', 'ICMP_IPV4_TYPE']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a631a793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['IN_BYTES',\n",
       "  'IN_PKTS',\n",
       "  'OUT_BYTES',\n",
       "  'RETRANSMITTED_OUT_BYTES',\n",
       "  'NUM_PKTS_1024_TO_1514_BYTES'],\n",
       " ['TCP_FLAGS', 'SERVER_TCP_FLAGS'],\n",
       " ['MIN_TTL'],\n",
       " ['LONGEST_FLOW_PKT', 'MAX_IP_PKT_LEN'],\n",
       " ['RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS'],\n",
       " ['ICMP_TYPE', 'ICMP_IPV4_TYPE']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correction because NUM_PKTS_1024_TO_1514_BYTES appears twice\n",
    "corr_list[2]=corr_list[2][:-1]\n",
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11152e01",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BasicGNN.__init__() missing 1 required positional argument: 'num_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Run for binary classification\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m run_model(data_binary, train_idx, test_idx, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Run for multi-class classification\u001b[39;00m\n\u001b[0;32m    122\u001b[0m run_model(data_multi, train_idx, test_idx, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-Class\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 69\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(data, train_idx, test_idx, num_classes, title)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_model\u001b[39m(data, train_idx, test_idx, num_classes, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 69\u001b[0m     model \u001b[38;5;241m=\u001b[39m GNN(in_channels\u001b[38;5;241m=\u001b[39mnum_features, hidden_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[0;32m     70\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m     71\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "Cell \u001b[1;32mIn[15], line 41\u001b[0m, in \u001b[0;36mGNN.__init__\u001b[1;34m(self, in_channels, hidden_channels, out_channels)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, hidden_channels, out_channels):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m GraphSAGE(in_channels, hidden_channels)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m GraphSAGE(hidden_channels, out_channels)\n",
      "\u001b[1;31mTypeError\u001b[0m: BasicGNN.__init__() missing 1 required positional argument: 'num_layers'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Simulated data (replace this with your actual features and labels)\n",
    "np.random.seed(42)\n",
    "num_nodes = 1000\n",
    "num_features = 16\n",
    "\n",
    "X = np.random.rand(num_nodes, num_features).astype(np.float32)\n",
    "y_binary = np.random.randint(0, 2, num_nodes)\n",
    "y_multi = np.random.randint(0, 5, num_nodes)\n",
    "\n",
    "edge_index = torch.randint(0, num_nodes, (2, 5000))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "train_idx, test_idx = train_test_split(np.arange(num_nodes), test_size=0.2, random_state=42)\n",
    "\n",
    "def create_data(X, y):\n",
    "    return Data(\n",
    "        x=torch.tensor(X, dtype=torch.float32),\n",
    "        edge_index=edge_index,\n",
    "        y=torch.tensor(y, dtype=torch.long)\n",
    "    )\n",
    "\n",
    "data_binary = create_data(X_scaled, y_binary)\n",
    "data_multi = create_data(X_scaled, y_multi)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphSAGE(in_channels, hidden_channels)\n",
    "        self.conv2 = GraphSAGE(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def train(model, data, idx, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = loss_fn(out[idx], data.y[idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(model, data, idx, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = loss_fn(out[idx], data.y[idx])\n",
    "        pred = out[idx].argmax(dim=1)\n",
    "        acc = accuracy_score(data.y[idx].cpu(), pred.cpu())\n",
    "    return loss, acc, pred\n",
    "\n",
    "def run_model(data, train_idx, test_idx, num_classes, title=\"\"):\n",
    "    model = GNN(in_channels=num_features, hidden_channels=32, out_channels=num_classes)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    epochs = 30\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accs, test_accs = [], []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        loss = train(model, data, train_idx, optimizer, loss_fn)\n",
    "        test_loss, test_acc, _ = evaluate(model, data, test_idx, loss_fn)\n",
    "        train_loss, train_acc, _ = evaluate(model, data, train_idx, loss_fn)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "    _, _, pred = evaluate(model, data, test_idx, loss_fn)\n",
    "    y_true = data.y[test_idx].cpu()\n",
    "    y_pred = pred.cpu()\n",
    "\n",
    "    print(f\"\\n{title} Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.title(f\"{title} Confusion Matrix\")\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot curves\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.title(f\"{title} - Loss Curve\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train Acc')\n",
    "    plt.plot(test_accs, label='Test Acc')\n",
    "    plt.title(f\"{title} - Accuracy Curve\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run for binary classification\n",
    "run_model(data_binary, train_idx, test_idx, num_classes=2, title=\"Binary\")\n",
    "\n",
    "# Run for multi-class classification\n",
    "run_model(data_multi, train_idx, test_idx, num_classes=5, title=\"Multi-Class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a9f8ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in c:\\users\\gech\\anaconda3\\lib\\site-packages (2.6.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: aiohttp in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (3.10.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (4.66.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\gech\\anaconda3\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\gech\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gech\\anaconda3\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\gech\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eef436",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch_geometric' has no attribute 'typing' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GATConv\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "File \u001b[1;32mc:\\Users\\gech\\anaconda3\\lib\\site-packages\\torch_geometric\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhome\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_home_dir, set_home_dir\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_mps_available, is_xpu_available, device\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01misinstance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_instance\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_debug_enabled, debug, set_debug\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gech\\anaconda3\\lib\\site-packages\\torch_geometric\\isinstance.py:7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch_geometric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtyping\u001b[49m\u001b[38;5;241m.\u001b[39mWITH_PT20:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_torch_instance\u001b[39m(obj: Any, \u001b[38;5;28mcls\u001b[39m: Union[Type, Tuple[Type]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch_geometric' has no attribute 'typing' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71ce8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GATConv\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Data Loading and Preprocessing\n",
    "def load_and_preprocess_data(file_path):\n",
    "    # Load data\n",
    "    data = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Handle negative port values\n",
    "    data['L4_SRC_PORT'] = data['L4_SRC_PORT'].abs()\n",
    "    data['L4_DST_PORT'] = data['L4_DST_PORT'].abs()\n",
    "    \n",
    "    # Select numerical features\n",
    "    numerical_features = [\n",
    "        'L4_SRC_PORT', 'L4_DST_PORT', 'IN_BYTES', 'IN_PKTS', \n",
    "        'OUT_BYTES', 'OUT_PKTS', 'TCP_WIN_MAX_IN', 'TCP_WIN_MAX_OUT'\n",
    "    ]\n",
    "    \n",
    "    # Handle missing values\n",
    "    data[numerical_features] = data[numerical_features].fillna(0)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_attack = LabelEncoder()\n",
    "    data['Attack_encoded'] = le_attack.fit_transform(data['Attack'])\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "    \n",
    "    return data, numerical_features, le_attack\n",
    "\n",
    "# 2. Exploratory Data Analysis\n",
    "def perform_eda(data, numerical_features):\n",
    "    print(\"\\nEDA Summary:\")\n",
    "    print(\"\\nDataset Shape:\", data.shape)\n",
    "    print(\"\\nMissing Values:\\n\", data.isnull().sum().sum())\n",
    "    print(\"\\nLabel Distribution:\\n\", data['Label'].value_counts())\n",
    "    print(\"\\nAttack Type Distribution:\\n\", data['Attack'].value_counts())\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(data[numerical_features].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.savefig('correlation_heatmap.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Attack type distribution plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='Attack', data=data)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Attack Type Distribution')\n",
    "    plt.savefig('attack_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "# 3. Graph Construction\n",
    "def create_graph_data(data, numerical_features, target_col='Label'):\n",
    "    # Create edge index based on similar source/destination ports\n",
    "    edge_index = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i+1, len(data)):\n",
    "            if (data.iloc[i]['L4_SRC_PORT'] == data.iloc[j]['L4_SRC_PORT'] or \n",
    "                data.iloc[i]['L4_DST_PORT'] == data.iloc[j]['L4_DST_PORT']):\n",
    "                edge_index.append([i, j])\n",
    "                edge_index.append([j, i])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Node features\n",
    "    x = torch.tensor(data[numerical_features].values, dtype=torch.float)\n",
    "    \n",
    "    # Labels\n",
    "    y = torch.tensor(data[target_col].values, dtype=torch.long)\n",
    "    \n",
    "    # Create PyG data object\n",
    "    graph_data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    # Create train/test mask\n",
    "    train_mask, test_mask = train_test_split(\n",
    "        range(len(data)), test_size=0.2, random_state=42, stratify=data[target_col]\n",
    "    )\n",
    "    graph_data.train_mask = torch.tensor(train_mask, dtype=torch.long)\n",
    "    graph_data.test_mask = torch.tensor(test_mask, dtype=torch.long)\n",
    "    \n",
    "    return graph_data\n",
    "\n",
    "# 4. Attention-based GNN Model\n",
    "class AttentionGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=4):\n",
    "        super(AttentionGNN, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads)\n",
    "        self.fc1 = nn.Linear(hidden_dim * heads, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# 5. Training Function\n",
    "def train_model(model, data, optimizer, criterion, epochs=100):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# 6. Evaluation Function\n",
    "def evaluate_model(model, data, le_attack=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(data).argmax(dim=1)\n",
    "        \n",
    "        # Get true and predicted labels\n",
    "        y_true = data.y[data.test_mask].numpy()\n",
    "        y_pred = pred[data.test_mask].numpy()\n",
    "        \n",
    "        # Classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        if le_attack is not None:\n",
    "            target_names = le_attack.classes_\n",
    "        else:\n",
    "            target_names = ['Benign', 'Malicious']\n",
    "        print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # ROC AUC for binary classification\n",
    "        if len(np.unique(data.y)) == 2:\n",
    "            probs = torch.softmax(model(data), dim=1)[:, 1]\n",
    "            roc_auc = roc_auc_score(y_true, probs[data.test_mask].numpy())\n",
    "            print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    file_path = \"../dataset/NF-BoT-IoT-V2.parquet\"\n",
    "    data, numerical_features, le_attack = load_and_preprocess_data(file_path)\n",
    "    \n",
    "    # Perform EDA\n",
    "    perform_eda(data, numerical_features)\n",
    "    \n",
    "    # Binary Classification\n",
    "    print(\"\\n=== Binary Classification ===\")\n",
    "    binary_graph = create_graph_data(data, numerical_features, 'Label')\n",
    "    \n",
    "    # Initialize model\n",
    "    binary_model = AttentionGNN(\n",
    "        input_dim=len(numerical_features),\n",
    "        hidden_dim=64,\n",
    "        output_dim=2\n",
    "    )\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = torch.optim.Adam(binary_model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train model\n",
    "    binary_losses = train_model(binary_model, binary_graph, optimizer, criterion)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(binary_model, binary_graph)\n",
    "    \n",
    "    # Multiclass Classification\n",
    "    print(\"\\n=== Multiclass Classification ===\")\n",
    "    multiclass_graph = create_graph_data(data, numerical_features, 'Attack_encoded')\n",
    "    \n",
    "    # Initialize model\n",
    "    multiclass_model = AttentionGNN(\n",
    "        input_dim=len(numerical_features),\n",
    "        hidden_dim=64,\n",
    "        output_dim=len(le_attack.classes_)\n",
    "    )\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = torch.optim.Adam(multiclass_model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train model\n",
    "    multiclass_losses = train_model(multiclass_model, multiclass_graph, optimizer, criterion)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(multiclass_model, multiclass_graph, le_attack)\n",
    "    \n",
    "    # Plot training losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(binary_losses, label='Binary Classification')\n",
    "    plt.plot(multiclass_losses, label='Multiclass Classification')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.savefig('training_loss.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1a3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
