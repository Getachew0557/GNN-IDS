{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6615ff8",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b44b00f",
   "metadata": {},
   "source": [
    "### Import Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf28aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score, accuracy_score\n",
    "from os import cpu_count\n",
    "from math import floor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# import shap\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671219f",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea579c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample shape: (999999, 45)\n"
     ]
    }
   ],
   "source": [
    "#data=pd.read_csv(\"../dataset/NF_TON_IoT_V2/NF-ToN-IoT-v2.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# File path\n",
    "csv_path = \"../dataset/NF_TON_IoT_V2/NF-ToN-IoT-v2.csv\"\n",
    "\n",
    "# STEP 1: Count total rows (without loading the file into memory)\n",
    "with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "# STEP 2: Calculate how many lines to skip\n",
    "sample_size = 1_000_000\n",
    "lines_to_skip = sorted(random.sample(range(1, total_lines), total_lines - sample_size))\n",
    "\n",
    "# STEP 3: Read just 1 million rows (skip most lines except header)\n",
    "data = pd.read_csv(csv_path, skiprows=lines_to_skip)\n",
    "\n",
    "# Confirm result\n",
    "print(f\"Loaded sample shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2d727",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d2187",
   "metadata": {},
   "source": [
    "### Summary of Stastics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb1e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>L4_SRC_PORT</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>L4_DST_PORT</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "      <th>Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>51466</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>15600</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.1.193</td>\n",
       "      <td>64035</td>\n",
       "      <td>8.8.8.8</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>5.126</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3579</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>53929</td>\n",
       "      <td>192.168.1.255</td>\n",
       "      <td>15600</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.1.193</td>\n",
       "      <td>49220</td>\n",
       "      <td>192.168.1.33</td>\n",
       "      <td>4444</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>151312</td>\n",
       "      <td>200</td>\n",
       "      <td>87548</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>16425</td>\n",
       "      <td>2941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ransomware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.1.193</td>\n",
       "      <td>49236</td>\n",
       "      <td>192.168.1.37</td>\n",
       "      <td>4444</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>168880</td>\n",
       "      <td>214</td>\n",
       "      <td>38472</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>16425</td>\n",
       "      <td>2898</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ransomware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IPV4_SRC_ADDR  L4_SRC_PORT    IPV4_DST_ADDR  L4_DST_PORT  PROTOCOL  \\\n",
       "0   192.168.1.79        51466  239.255.255.250        15600        17   \n",
       "1  192.168.1.193        64035          8.8.8.8           53        17   \n",
       "2   192.168.1.79        53929    192.168.1.255        15600        17   \n",
       "3  192.168.1.193        49220     192.168.1.33         4444         6   \n",
       "4  192.168.1.193        49236     192.168.1.37         4444         6   \n",
       "\n",
       "   L7_PROTO  IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  ...  TCP_WIN_MAX_IN  \\\n",
       "0     0.000        63        1          0         0  ...               0   \n",
       "1     5.126        58        1         90         1  ...               0   \n",
       "2     0.000        63        1          0         0  ...               0   \n",
       "3     0.000    151312      200      87548       167  ...           16425   \n",
       "4     0.000    168880      214      38472       151  ...           16425   \n",
       "\n",
       "   TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0                0          0               0             0               0   \n",
       "1                0          0               0          3579               1   \n",
       "2                0          0               0             0               0   \n",
       "3             2941          0               0             0               0   \n",
       "4             2898          0               0             0               0   \n",
       "\n",
       "   DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  Label      Attack  \n",
       "0               0                     0      0      Benign  \n",
       "1             299                     0      0      Benign  \n",
       "2               0                     0      0      Benign  \n",
       "3               0                     0      1  ransomware  \n",
       "4               0                     0      1  ransomware  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad56ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPV4_SRC_ADDR                   object\n",
       "L4_SRC_PORT                      int64\n",
       "IPV4_DST_ADDR                   object\n",
       "L4_DST_PORT                      int64\n",
       "PROTOCOL                         int64\n",
       "L7_PROTO                       float64\n",
       "IN_BYTES                         int64\n",
       "IN_PKTS                          int64\n",
       "OUT_BYTES                        int64\n",
       "OUT_PKTS                         int64\n",
       "TCP_FLAGS                        int64\n",
       "CLIENT_TCP_FLAGS                 int64\n",
       "SERVER_TCP_FLAGS                 int64\n",
       "FLOW_DURATION_MILLISECONDS       int64\n",
       "DURATION_IN                      int64\n",
       "DURATION_OUT                     int64\n",
       "MIN_TTL                          int64\n",
       "MAX_TTL                          int64\n",
       "LONGEST_FLOW_PKT                 int64\n",
       "SHORTEST_FLOW_PKT                int64\n",
       "MIN_IP_PKT_LEN                   int64\n",
       "MAX_IP_PKT_LEN                   int64\n",
       "SRC_TO_DST_SECOND_BYTES        float64\n",
       "DST_TO_SRC_SECOND_BYTES        float64\n",
       "RETRANSMITTED_IN_BYTES           int64\n",
       "RETRANSMITTED_IN_PKTS            int64\n",
       "RETRANSMITTED_OUT_BYTES          int64\n",
       "RETRANSMITTED_OUT_PKTS           int64\n",
       "SRC_TO_DST_AVG_THROUGHPUT        int64\n",
       "DST_TO_SRC_AVG_THROUGHPUT        int64\n",
       "NUM_PKTS_UP_TO_128_BYTES         int64\n",
       "NUM_PKTS_128_TO_256_BYTES        int64\n",
       "NUM_PKTS_256_TO_512_BYTES        int64\n",
       "NUM_PKTS_512_TO_1024_BYTES       int64\n",
       "NUM_PKTS_1024_TO_1514_BYTES      int64\n",
       "TCP_WIN_MAX_IN                   int64\n",
       "TCP_WIN_MAX_OUT                  int64\n",
       "ICMP_TYPE                        int64\n",
       "ICMP_IPV4_TYPE                   int64\n",
       "DNS_QUERY_ID                     int64\n",
       "DNS_QUERY_TYPE                   int64\n",
       "DNS_TTL_ANSWER                   int64\n",
       "FTP_COMMAND_RET_CODE             int64\n",
       "Label                            int64\n",
       "Attack                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ce873e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    639952\n",
       "0    360047\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7e5bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack\n",
       "Benign        360047\n",
       "scanning      222925\n",
       "xss           144988\n",
       "ddos          119472\n",
       "password       68375\n",
       "dos            42024\n",
       "injection      40518\n",
       "backdoor         977\n",
       "mitm             468\n",
       "ransomware       205\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcaec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['L4_SRC_PORT', 'L4_DST_PORT']) #dropping metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d96873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = data.sample(frac=0.05, replace=False,random_state=42)\n",
    "# 1%train, 99% test\n",
    "testing_set = data.drop(index=training_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "324c1ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack\n",
       "Benign        18040\n",
       "scanning      11293\n",
       "xss            7194\n",
       "ddos           5902\n",
       "password       3403\n",
       "dos            2063\n",
       "injection      2024\n",
       "backdoor         56\n",
       "mitm             13\n",
       "ransomware       12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.Attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b8d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks=training_set.Attack.unique()\n",
    "attacks=['Benign','Reconnaissance', 'DDoS', 'DoS', 'Theft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a08dc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1: ['IN_BYTES', 'IN_PKTS', 'OUT_BYTES', 'RETRANSMITTED_OUT_BYTES', 'NUM_PKTS_1024_TO_1514_BYTES']\n",
      "Group 2: ['TCP_FLAGS', 'SERVER_TCP_FLAGS']\n",
      "Group 3: ['MIN_TTL', 'MAX_TTL']\n",
      "Group 4: ['LONGEST_FLOW_PKT', 'MAX_IP_PKT_LEN']\n",
      "Group 5: ['RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS']\n",
      "Group 6: ['ICMP_TYPE', 'ICMP_IPV4_TYPE']\n"
     ]
    }
   ],
   "source": [
    "# --- Compute correlation only for numeric features ---\n",
    "corr = training_set.select_dtypes(include='number').corr()\n",
    "\n",
    "# Find highly correlated features (> 0.9)\n",
    "corr_features = {\n",
    "    corr.columns[i]: corr.columns[(corr > 0.9).iloc[i]].values.tolist()\n",
    "    for i in range(corr.shape[0])\n",
    "}\n",
    "\n",
    "# Group correlated features into sets (no duplicates)\n",
    "corr_list = []\n",
    "for key, value in corr_features.items():\n",
    "    have_set = any(key in s for s in corr_list)\n",
    "    if not have_set and len(value) > 1:\n",
    "        corr_list.append(value)\n",
    "\n",
    "# Output the groups of highly correlated features\n",
    "for i, group in enumerate(corr_list, 1):\n",
    "    print(f\"Group {i}: {group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f90e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['IN_BYTES',\n",
       "  'IN_PKTS',\n",
       "  'OUT_BYTES',\n",
       "  'RETRANSMITTED_OUT_BYTES',\n",
       "  'NUM_PKTS_1024_TO_1514_BYTES'],\n",
       " ['TCP_FLAGS', 'SERVER_TCP_FLAGS'],\n",
       " ['MIN_TTL', 'MAX_TTL'],\n",
       " ['LONGEST_FLOW_PKT', 'MAX_IP_PKT_LEN'],\n",
       " ['RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS'],\n",
       " ['ICMP_TYPE', 'ICMP_IPV4_TYPE']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a631a793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['IN_BYTES',\n",
       "  'IN_PKTS',\n",
       "  'OUT_BYTES',\n",
       "  'RETRANSMITTED_OUT_BYTES',\n",
       "  'NUM_PKTS_1024_TO_1514_BYTES'],\n",
       " ['TCP_FLAGS', 'SERVER_TCP_FLAGS'],\n",
       " ['MIN_TTL'],\n",
       " ['LONGEST_FLOW_PKT', 'MAX_IP_PKT_LEN'],\n",
       " ['RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS'],\n",
       " ['ICMP_TYPE', 'ICMP_IPV4_TYPE']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correction because NUM_PKTS_1024_TO_1514_BYTES appears twice\n",
    "corr_list[2]=corr_list[2][:-1]\n",
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11152e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample shape: (1000000, 45)\n",
      "\n",
      "=== Binary Classification ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gech\\AppData\\Local\\Temp\\ipykernel_20852\\1267434294.py:122: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  x = torch.tensor(x, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Graph constructed: 65273 nodes, 2000000 edges\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MessagePassing.__init__() got an unexpected keyword argument 'edge_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 300\u001b[0m\n\u001b[0;32m    298\u001b[0m df_processed_bin, y_bin, num_classes_bin, _, class_names_bin, edge_features_bin, edge_feature_cols \u001b[38;5;241m=\u001b[39m prepare_data(data, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    299\u001b[0m data_graph_bin \u001b[38;5;241m=\u001b[39m build_graph(df_processed_bin, y_bin, edge_features_bin, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 300\u001b[0m model_bin \u001b[38;5;241m=\u001b[39m EGraphSAGEModel(data_graph_bin\u001b[38;5;241m.\u001b[39mnum_features, \u001b[38;5;28mlen\u001b[39m(edge_feature_cols), num_classes_bin)\n\u001b[0;32m    301\u001b[0m train_evaluate(model_bin, data_graph_bin, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, num_classes_bin, class_names_bin)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# Multiclass classification\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 136\u001b[0m, in \u001b[0;36mEGraphSAGEModel.__init__\u001b[1;34m(self, num_features, num_edge_features, num_classes)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_features, num_edge_features, num_classes):\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28msuper\u001b[39m(EGraphSAGEModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m SAGEConv(num_features, \u001b[38;5;241m64\u001b[39m, edge_dim\u001b[38;5;241m=\u001b[39mnum_edge_features)\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m SAGEConv(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, edge_dim\u001b[38;5;241m=\u001b[39mnum_edge_features)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, num_classes)\n",
      "File \u001b[1;32mc:\\Users\\gech\\anaconda3\\Lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:91\u001b[0m, in \u001b[0;36mSAGEConv.__init__\u001b[1;34m(self, in_channels, out_channels, aggr, normalize, root_weight, project, bias, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggr_kwargs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_channels\u001b[39m\u001b[38;5;124m'\u001b[39m, in_channels[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     89\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggr_kwargs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_channels\u001b[39m\u001b[38;5;124m'\u001b[39m, in_channels[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(aggr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m in_channels[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: MessagePassing.__init__() got an unexpected keyword argument 'edge_dim'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load dataset with sampling\n",
    "csv_path = \"../dataset/NF_TON_IoT_V2/NF-ToN-IoT-v2.csv\"\n",
    "with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "    total_lines = sum(1 for _ in f) - 1  # Exclude header\n",
    "sample_size = 1_000_000\n",
    "lines_to_skip = sorted(random.sample(range(1, total_lines + 1), total_lines - sample_size))\n",
    "data = pd.read_csv(csv_path, skiprows=lines_to_skip)\n",
    "print(f\"Loaded sample shape: {data.shape}\")\n",
    "\n",
    "# Handle missing values\n",
    "for col in data.columns:\n",
    "    if data[col].dtype in ['int64', 'float64']:\n",
    "        data[col] = data[col].fillna(data[col].mean())\n",
    "    else:\n",
    "        data[col] = data[col].fillna(0)\n",
    "\n",
    "# Encode categorical features\n",
    "le_protocol = LabelEncoder()\n",
    "data['PROTOCOL'] = le_protocol.fit_transform(data['PROTOCOL'].astype(str))\n",
    "le_l7_proto = LabelEncoder()\n",
    "data['L7_PROTO'] = le_l7_proto.fit_transform(data['L7_PROTO'].astype(str))\n",
    "\n",
    "# Function to prepare data\n",
    "def prepare_data(df, mode='binary'):\n",
    "    if mode == 'binary':\n",
    "        y = df['Label'].values\n",
    "        num_classes = 2\n",
    "        le_attack = None\n",
    "        class_names = ['Benign', 'Attack']\n",
    "    elif mode == 'multiclass':\n",
    "        le_attack = LabelEncoder()\n",
    "        df['Attack'] = le_attack.fit_transform(df['Attack'].astype(str))\n",
    "        y = df['Attack'].values\n",
    "        unique_y = np.unique(y)\n",
    "        num_classes = len(unique_y)\n",
    "        label_map = {old: new for new, old in enumerate(unique_y)}\n",
    "        y = np.array([label_map[yi] for yi in y])\n",
    "        class_names = [le_attack.classes_[unique_y[i]] for i in range(num_classes)]\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'binary' or 'multiclass'\")\n",
    "\n",
    "    # Select numerical features (exclude Label, Attack, IP addresses, and ports)\n",
    "    feature_cols = [col for col in df.columns if col not in ['Label', 'Attack', 'IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'L4_SRC_PORT', 'L4_DST_PORT']]\n",
    "    X = df[feature_cols].values\n",
    "\n",
    "    # Normalize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Create preprocessed DataFrame\n",
    "    df_processed = pd.DataFrame(X, columns=feature_cols)\n",
    "    df_processed[mode.capitalize()] = y\n",
    "    df_processed['L4_SRC_PORT'] = df['L4_SRC_PORT'].values\n",
    "    df_processed['L4_DST_PORT'] = df['L4_DST_PORT'].values\n",
    "\n",
    "    # Edge features (e.g., IN_BYTES, OUT_BYTES, IN_PKTS, OUT_PKTS)\n",
    "    edge_feature_cols = ['IN_BYTES', 'OUT_BYTES', 'IN_PKTS', 'OUT_PKTS']\n",
    "    edge_features = df[edge_feature_cols].values\n",
    "    edge_scaler = StandardScaler()\n",
    "    edge_features = edge_scaler.fit_transform(edge_features)\n",
    "\n",
    "    return df_processed, y, num_classes, le_attack, class_names, edge_features, edge_feature_cols\n",
    "\n",
    "# Function for graph construction with edge features\n",
    "def build_graph(df_processed, y, edge_features, mode):\n",
    "    src_ports = df_processed['L4_SRC_PORT'].values\n",
    "    dst_ports = df_processed['L4_DST_PORT'].values\n",
    "    unique_ports = np.unique(np.concatenate([src_ports, dst_ports]))\n",
    "    port_to_idx = {port: idx for idx, port in enumerate(unique_ports)}\n",
    "\n",
    "    node_features = defaultdict(list)\n",
    "    node_labels = defaultdict(list)\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    for idx in range(len(df_processed)):\n",
    "        row = df_processed.iloc[idx]\n",
    "        src_port = row['L4_SRC_PORT']\n",
    "        dst_port = row['L4_DST_PORT']\n",
    "        features = row.drop([mode.capitalize(), 'L4_SRC_PORT', 'L4_DST_PORT']).values\n",
    "        label = row[mode.capitalize()]\n",
    "        src_idx = port_to_idx[src_port]\n",
    "        dst_idx = port_to_idx[dst_port]\n",
    "        node_features[src_idx].append(features)\n",
    "        node_features[dst_idx].append(features)\n",
    "        node_labels[src_idx].append(label)\n",
    "        node_labels[dst_idx].append(label)\n",
    "        edge_index.append([src_idx, dst_idx])\n",
    "        edge_index.append([dst_idx, src_idx])\n",
    "        edge_attr.append(edge_features[idx])\n",
    "        edge_attr.append(edge_features[idx])  # Bidirectional\n",
    "\n",
    "    x = []\n",
    "    y_graph = []\n",
    "    for port_idx in range(len(unique_ports)):\n",
    "        if port_idx in node_features:\n",
    "            x.append(np.mean(node_features[port_idx], axis=0))\n",
    "            labels = node_labels[port_idx]\n",
    "            y_graph.append(np.bincount(labels).argmax())\n",
    "        else:\n",
    "            x.append(np.zeros(df_processed.shape[1] - 3))\n",
    "            y_graph.append(0)\n",
    "\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    y_graph = torch.tensor(y_graph, dtype=torch.long)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    data_graph = Data(x=x, edge_index=edge_index, y=y_graph, edge_attr=edge_attr)\n",
    "    print(f\"{mode.capitalize()} Graph constructed: {data_graph.num_nodes} nodes, {data_graph.num_edges} edges\")\n",
    "\n",
    "    return data_graph\n",
    "\n",
    "# E-GraphSAGE model\n",
    "class EGraphSAGEModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_edge_features, num_classes):\n",
    "        super(EGraphSAGEModel, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_features, 64, edge_dim=num_edge_features)\n",
    "        self.conv2 = SAGEConv(64, 64, edge_dim=num_edge_features)\n",
    "        self.fc = torch.nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_evaluate(model, data_graph, mode, num_classes, class_names, max_epochs=100, patience=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    # Masks\n",
    "    num_nodes = data_graph.num_nodes\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    indices = np.random.permutation(num_nodes)\n",
    "    train_size = int(0.6 * num_nodes)\n",
    "    val_size = int(0.2 * num_nodes)\n",
    "    train_mask[indices[:train_size]] = True\n",
    "    val_mask[indices[train_size:train_size + val_size]] = True\n",
    "    test_mask[indices[train_size + val_size:]] = True\n",
    "    data_graph.train_mask = train_mask\n",
    "    data_graph.val_mask = val_mask\n",
    "    data_graph.test_mask = test_mask\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data_graph)\n",
    "        loss = F.nll_loss(out[data_graph.train_mask], data_graph.y[data_graph.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        train_acc = accuracy_score(data_graph.y[data_graph.train_mask].numpy(), pred[data_graph.train_mask].numpy())\n",
    "        train_losses.append(loss.item())\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data_graph)\n",
    "            val_loss = F.nll_loss(out[data_graph.val_mask], data_graph.y[data_graph.val_mask])\n",
    "            val_pred = out.argmax(dim=1)\n",
    "            val_acc = accuracy_score(data_graph.y[data_graph.val_mask].numpy(), val_pred[data_graph.val_mask].numpy())\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f'{mode.capitalize()} Epoch {epoch + 1}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'{mode.capitalize()} Early stopping at epoch {epoch + 1}')\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Plots for accuracy and loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_accuracies, label='Train Acc')\n",
    "    plt.plot(val_accuracies, label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{mode.capitalize()} Training vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{mode.capitalize()} Training vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{mode}_acc_loss.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data_graph)\n",
    "        pred = out.argmax(dim=1)\n",
    "        y_true = data_graph.y[data_graph.test_mask].numpy()\n",
    "        y_pred = pred[data_graph.test_mask].numpy()\n",
    "        y_score = out[data_graph.test_mask].numpy()\n",
    "\n",
    "        test_classes = np.unique(y_true)\n",
    "        test_class_names = [class_names[i] for i in test_classes]\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='weighted', labels=test_classes)\n",
    "        recall = recall_score(y_true, y_pred, average='weighted', labels=test_classes)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted', labels=test_classes)\n",
    "\n",
    "        print(f\"\\n{mode.capitalize()} Classification Report:\")\n",
    "        print(classification_report(y_true, y_pred, labels=test_classes, target_names=test_class_names))\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=test_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_class_names, yticklabels=test_class_names)\n",
    "        plt.title(f'{mode.capitalize()} Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(f'{mode}_confusion_matrix.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        if mode == 'binary':\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_score[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'{mode.capitalize()} ROC Curve')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.savefig(f'{mode}_roc_curve.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        else:\n",
    "            y_true_bin = label_binarize(y_true, classes=range(num_classes))\n",
    "            plt.figure()\n",
    "            for i in test_classes:\n",
    "                fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                plt.plot(fpr, tpr, label=f'Class {test_class_names[list(test_classes).index(i)]} (AUC = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'{mode.capitalize()} ROC Curve (One-vs-Rest)')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.savefig(f'{mode}_roc_curve.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    print(f\"\\n{mode.capitalize()} Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (weighted): {recall:.4f}\")\n",
    "    print(f\"F1 (weighted): {f1:.4f}\")\n",
    "\n",
    "# Binary classification\n",
    "print(\"\\n=== Binary Classification ===\")\n",
    "df_processed_bin, y_bin, num_classes_bin, _, class_names_bin, edge_features_bin, edge_feature_cols = prepare_data(data, mode='binary')\n",
    "data_graph_bin = build_graph(df_processed_bin, y_bin, edge_features_bin, 'binary')\n",
    "model_bin = EGraphSAGEModel(data_graph_bin.num_features, len(edge_feature_cols), num_classes_bin)\n",
    "train_evaluate(model_bin, data_graph_bin, 'binary', num_classes_bin, class_names_bin)\n",
    "\n",
    "# Multiclass classification\n",
    "print(\"\\n=== Multiclass Classification ===\")\n",
    "df_processed_multi, y_multi, num_classes_multi, le_attack_multi, class_names_multi, edge_features_multi, edge_feature_cols = prepare_data(data, mode='multiclass')\n",
    "data_graph_multi = build_graph(df_processed_multi, y_multi, edge_features_multi, 'multiclass')\n",
    "model_multi = EGraphSAGEModel(data_graph_multi.num_features, len(edge_feature_cols), num_classes_multi)\n",
    "train_evaluate(model_multi, data_graph_multi, 'multiclass', num_classes_multi, class_names_multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a9f8ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in c:\\users\\gech\\anaconda3\\lib\\site-packages (2.6.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: aiohttp in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (3.10.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch-geometric) (4.66.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\gech\\anaconda3\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\gech\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gech\\anaconda3\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\gech\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\gech\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eef436",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch_geometric' has no attribute 'typing' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GATConv\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "File \u001b[1;32mc:\\Users\\gech\\anaconda3\\lib\\site-packages\\torch_geometric\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhome\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_home_dir, set_home_dir\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_mps_available, is_xpu_available, device\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01misinstance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_instance\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_debug_enabled, debug, set_debug\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gech\\anaconda3\\lib\\site-packages\\torch_geometric\\isinstance.py:7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch_geometric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtyping\u001b[49m\u001b[38;5;241m.\u001b[39mWITH_PT20:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_torch_instance\u001b[39m(obj: Any, \u001b[38;5;28mcls\u001b[39m: Union[Type, Tuple[Type]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch_geometric' has no attribute 'typing' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71ce8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GATConv\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Data Loading and Preprocessing\n",
    "def load_and_preprocess_data(file_path):\n",
    "    # Load data\n",
    "    data = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Handle negative port values\n",
    "    data['L4_SRC_PORT'] = data['L4_SRC_PORT'].abs()\n",
    "    data['L4_DST_PORT'] = data['L4_DST_PORT'].abs()\n",
    "    \n",
    "    # Select numerical features\n",
    "    numerical_features = [\n",
    "        'L4_SRC_PORT', 'L4_DST_PORT', 'IN_BYTES', 'IN_PKTS', \n",
    "        'OUT_BYTES', 'OUT_PKTS', 'TCP_WIN_MAX_IN', 'TCP_WIN_MAX_OUT'\n",
    "    ]\n",
    "    \n",
    "    # Handle missing values\n",
    "    data[numerical_features] = data[numerical_features].fillna(0)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_attack = LabelEncoder()\n",
    "    data['Attack_encoded'] = le_attack.fit_transform(data['Attack'])\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "    \n",
    "    return data, numerical_features, le_attack\n",
    "\n",
    "# 2. Exploratory Data Analysis\n",
    "def perform_eda(data, numerical_features):\n",
    "    print(\"\\nEDA Summary:\")\n",
    "    print(\"\\nDataset Shape:\", data.shape)\n",
    "    print(\"\\nMissing Values:\\n\", data.isnull().sum().sum())\n",
    "    print(\"\\nLabel Distribution:\\n\", data['Label'].value_counts())\n",
    "    print(\"\\nAttack Type Distribution:\\n\", data['Attack'].value_counts())\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(data[numerical_features].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.savefig('correlation_heatmap.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Attack type distribution plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='Attack', data=data)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Attack Type Distribution')\n",
    "    plt.savefig('attack_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "# 3. Graph Construction\n",
    "def create_graph_data(data, numerical_features, target_col='Label'):\n",
    "    # Create edge index based on similar source/destination ports\n",
    "    edge_index = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i+1, len(data)):\n",
    "            if (data.iloc[i]['L4_SRC_PORT'] == data.iloc[j]['L4_SRC_PORT'] or \n",
    "                data.iloc[i]['L4_DST_PORT'] == data.iloc[j]['L4_DST_PORT']):\n",
    "                edge_index.append([i, j])\n",
    "                edge_index.append([j, i])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Node features\n",
    "    x = torch.tensor(data[numerical_features].values, dtype=torch.float)\n",
    "    \n",
    "    # Labels\n",
    "    y = torch.tensor(data[target_col].values, dtype=torch.long)\n",
    "    \n",
    "    # Create PyG data object\n",
    "    graph_data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    # Create train/test mask\n",
    "    train_mask, test_mask = train_test_split(\n",
    "        range(len(data)), test_size=0.2, random_state=42, stratify=data[target_col]\n",
    "    )\n",
    "    graph_data.train_mask = torch.tensor(train_mask, dtype=torch.long)\n",
    "    graph_data.test_mask = torch.tensor(test_mask, dtype=torch.long)\n",
    "    \n",
    "    return graph_data\n",
    "\n",
    "# 4. Attention-based GNN Model\n",
    "class AttentionGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=4):\n",
    "        super(AttentionGNN, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads)\n",
    "        self.fc1 = nn.Linear(hidden_dim * heads, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# 5. Training Function\n",
    "def train_model(model, data, optimizer, criterion, epochs=100):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# 6. Evaluation Function\n",
    "def evaluate_model(model, data, le_attack=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(data).argmax(dim=1)\n",
    "        \n",
    "        # Get true and predicted labels\n",
    "        y_true = data.y[data.test_mask].numpy()\n",
    "        y_pred = pred[data.test_mask].numpy()\n",
    "        \n",
    "        # Classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        if le_attack is not None:\n",
    "            target_names = le_attack.classes_\n",
    "        else:\n",
    "            target_names = ['Benign', 'Malicious']\n",
    "        print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # ROC AUC for binary classification\n",
    "        if len(np.unique(data.y)) == 2:\n",
    "            probs = torch.softmax(model(data), dim=1)[:, 1]\n",
    "            roc_auc = roc_auc_score(y_true, probs[data.test_mask].numpy())\n",
    "            print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    file_path = \"../dataset/NF-BoT-IoT-V2.parquet\"\n",
    "    data, numerical_features, le_attack = load_and_preprocess_data(file_path)\n",
    "    \n",
    "    # Perform EDA\n",
    "    perform_eda(data, numerical_features)\n",
    "    \n",
    "    # Binary Classification\n",
    "    print(\"\\n=== Binary Classification ===\")\n",
    "    binary_graph = create_graph_data(data, numerical_features, 'Label')\n",
    "    \n",
    "    # Initialize model\n",
    "    binary_model = AttentionGNN(\n",
    "        input_dim=len(numerical_features),\n",
    "        hidden_dim=64,\n",
    "        output_dim=2\n",
    "    )\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = torch.optim.Adam(binary_model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train model\n",
    "    binary_losses = train_model(binary_model, binary_graph, optimizer, criterion)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(binary_model, binary_graph)\n",
    "    \n",
    "    # Multiclass Classification\n",
    "    print(\"\\n=== Multiclass Classification ===\")\n",
    "    multiclass_graph = create_graph_data(data, numerical_features, 'Attack_encoded')\n",
    "    \n",
    "    # Initialize model\n",
    "    multiclass_model = AttentionGNN(\n",
    "        input_dim=len(numerical_features),\n",
    "        hidden_dim=64,\n",
    "        output_dim=len(le_attack.classes_)\n",
    "    )\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = torch.optim.Adam(multiclass_model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Train model\n",
    "    multiclass_losses = train_model(multiclass_model, multiclass_graph, optimizer, criterion)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(multiclass_model, multiclass_graph, le_attack)\n",
    "    \n",
    "    # Plot training losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(binary_losses, label='Binary Classification')\n",
    "    plt.plot(multiclass_losses, label='Multiclass Classification')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.savefig('training_loss.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1a3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
